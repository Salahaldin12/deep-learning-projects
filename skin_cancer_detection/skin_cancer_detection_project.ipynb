{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b0ccab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T13:48:44.374430Z",
     "start_time": "2023-07-23T13:48:39.673170Z"
    }
   },
   "outputs": [],
   "source": [
    "#import Libraries\n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers ,models ,Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator ,load_img ,img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input , decode_predictions,ResNet50\n",
    "from tensorflow.keras.layers import Conv2D,Flatten,Dense,MaxPool2D,BatchNormalization,GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0368f7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T13:48:45.402907Z",
     "start_time": "2023-07-23T13:48:45.391890Z"
    }
   },
   "outputs": [],
   "source": [
    "#Putting data into variables\n",
    "img_height, img_width = (64,64)\n",
    "batch_size= 32\n",
    "train_data = f\"data/train\"\n",
    "test_data = f\"data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2694e174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T13:48:46.581591Z",
     "start_time": "2023-07-23T13:48:46.402877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2637 images belonging to 2 classes.\n",
      "Found 660 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Divide into testing, training and validation\n",
    "train_data_1 = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  validation_split=0.4)\n",
    "train_img = train_data_1.flow_from_directory(train_data,\n",
    "                                               target_size=(img_height,img_width),\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode=\"categorical\")\n",
    "test_img = train_data_1.flow_from_directory(test_data,\n",
    "                                               target_size=(img_height,img_width),\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0918d1f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T13:48:48.113334Z",
     "start_time": "2023-07-23T13:48:47.940583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64, 64, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = test_img.next()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69777084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T13:52:30.030471Z",
     "start_time": "2023-07-23T13:48:50.782031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "83/83 [==============================] - 23s 232ms/step - loss: 1.0372 - accuracy: 0.7960\n",
      "Epoch 2/10\n",
      "83/83 [==============================] - 19s 231ms/step - loss: 0.3279 - accuracy: 0.8525\n",
      "Epoch 3/10\n",
      "83/83 [==============================] - 20s 243ms/step - loss: 0.2864 - accuracy: 0.8760\n",
      "Epoch 4/10\n",
      "83/83 [==============================] - 20s 246ms/step - loss: 0.2784 - accuracy: 0.8779\n",
      "Epoch 5/10\n",
      "83/83 [==============================] - 20s 242ms/step - loss: 0.2608 - accuracy: 0.8726\n",
      "Epoch 6/10\n",
      "83/83 [==============================] - 21s 252ms/step - loss: 0.2325 - accuracy: 0.8980\n",
      "Epoch 7/10\n",
      "83/83 [==============================] - 22s 261ms/step - loss: 0.2236 - accuracy: 0.8995\n",
      "Epoch 8/10\n",
      "83/83 [==============================] - 20s 245ms/step - loss: 0.2293 - accuracy: 0.8991\n",
      "Epoch 9/10\n",
      "83/83 [==============================] - 25s 298ms/step - loss: 0.2105 - accuracy: 0.9124\n",
      "Epoch 10/10\n",
      "83/83 [==============================] - 25s 298ms/step - loss: 0.2147 - accuracy: 0.9105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1c8f56820>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating and training neural networks\n",
    "model_cs = ResNet50(include_top=False,weights=\"imagenet\")\n",
    "x = model_cs.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation=\"relu\")(x)\n",
    "pred = Dense(train_img.num_classes,activation='softmax')(x)\n",
    "model = Model(inputs=model_cs.input,outputs=pred)\n",
    "for layer in model_cs.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_img, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77e8435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T13:52:38.974656Z",
     "start_time": "2023-07-23T13:52:32.540673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 6s 234ms/step - loss: 0.3509 - accuracy: 0.8455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35093724727630615, 0.8454545736312866]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d993654",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:08:34.392566Z",
     "start_time": "2023-07-23T14:05:40.716547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "83/83 [==============================] - 17s 197ms/step - loss: 2.1788 - accuracy: 0.6959\n",
      "Epoch 2/10\n",
      "83/83 [==============================] - 16s 197ms/step - loss: 0.4514 - accuracy: 0.7801\n",
      "Epoch 3/10\n",
      "83/83 [==============================] - 18s 213ms/step - loss: 0.3981 - accuracy: 0.8142\n",
      "Epoch 4/10\n",
      "83/83 [==============================] - 19s 225ms/step - loss: 0.3918 - accuracy: 0.8153\n",
      "Epoch 5/10\n",
      "83/83 [==============================] - 19s 231ms/step - loss: 0.4101 - accuracy: 0.8032\n",
      "Epoch 6/10\n",
      "83/83 [==============================] - 18s 210ms/step - loss: 0.3916 - accuracy: 0.8172\n",
      "Epoch 7/10\n",
      "83/83 [==============================] - 17s 200ms/step - loss: 0.3630 - accuracy: 0.8237\n",
      "Epoch 8/10\n",
      "83/83 [==============================] - 17s 199ms/step - loss: 0.3466 - accuracy: 0.8377\n",
      "Epoch 9/10\n",
      "83/83 [==============================] - 17s 201ms/step - loss: 0.3479 - accuracy: 0.8377\n",
      "Epoch 10/10\n",
      "83/83 [==============================] - 17s 201ms/step - loss: 0.3375 - accuracy: 0.8411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1d7782a00>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = Sequential([\n",
    "                  layers.Conv2D(128, (2,2), activation='relu', input_shape=(64, 64, 3)),\n",
    "                  layers.MaxPooling2D(3,3),\n",
    "                  layers.Conv2D(128, kernel_size=(3,3),activation='relu',kernel_initializer='he_normal'),\n",
    "                  layers.MaxPooling2D(2,2),\n",
    "                  #layers.Conv2D(64, (2, 2), activation='relu'),\n",
    "                  layers.Conv2D(128, kernel_size=(2,2),activation='relu',kernel_initializer='he_normal'),\n",
    "                  layers.MaxPooling2D(2,2),\n",
    "                  layers.Flatten(),\n",
    "                  layers.Dense(128,activation='relu'),\n",
    "                  layers.Dense(2,activation='softmax',kernel_initializer='glorot_normal')\n",
    "                  \n",
    "])\n",
    "cnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "cnn.fit(train_img, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53c1b340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:08:48.259495Z",
     "start_time": "2023-07-23T14:08:45.592488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 3s 112ms/step - loss: 0.4045 - accuracy: 0.8152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40453600883483887, 0.8151515126228333]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578d8dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f0f218f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:09:15.150184Z",
     "start_time": "2023-07-23T14:09:15.065142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'malignant'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_image = load_img('3.jpg', target_size = (64, 64))\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "#training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'benign'\n",
    "else:\n",
    "    prediction = 'malignant'\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
