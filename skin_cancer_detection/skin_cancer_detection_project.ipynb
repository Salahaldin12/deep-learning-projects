{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70b0ccab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T00:09:33.541703Z",
     "start_time": "2022-10-03T00:09:33.530640Z"
    }
   },
   "outputs": [],
   "source": [
    "#link data :https://www.kaggle.com/datasets/wanderdust/skin-lesion-analysis-toward-melanoma-detection\n",
    "#import Libraries\n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers ,models ,Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator ,load_img ,img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input , decode_predictions,ResNet50\n",
    "from tensorflow.keras.layers import Conv2D,Flatten,Dense,MaxPool2D,BatchNormalization,GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0368f7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-02T23:47:42.769636Z",
     "start_time": "2022-10-02T23:47:42.762201Z"
    }
   },
   "outputs": [],
   "source": [
    "#Putting data into variables\n",
    "img_height, img_width = (64,64)\n",
    "batch_size= 32\n",
    "train_data = f\"data/train\"\n",
    "test_data = f\"data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2694e174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-02T23:47:43.703646Z",
     "start_time": "2022-10-02T23:47:43.539043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2637 images belonging to 2 classes.\n",
      "Found 660 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Divide into testing, training and validation\n",
    "train_data_1 = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  validation_split=0.4)\n",
    "train_img = train_data_1.flow_from_directory(train_data,\n",
    "                                               target_size=(img_height,img_width),\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode=\"categorical\")\n",
    "test_img = train_data_1.flow_from_directory(test_data,\n",
    "                                               target_size=(img_height,img_width),\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0918d1f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-02T23:47:59.497108Z",
     "start_time": "2022-10-02T23:47:59.383359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64, 64, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = test_img.next()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69777084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T00:06:59.732349Z",
     "start_time": "2022-10-03T00:03:52.968307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "83/83 [==============================] - 23s 229ms/step - loss: 1.1989 - accuracy: 0.7892\n",
      "Epoch 2/10\n",
      "83/83 [==============================] - 18s 219ms/step - loss: 0.3112 - accuracy: 0.8559\n",
      "Epoch 3/10\n",
      "83/83 [==============================] - 18s 219ms/step - loss: 0.2933 - accuracy: 0.8673\n",
      "Epoch 4/10\n",
      "83/83 [==============================] - 18s 217ms/step - loss: 0.2762 - accuracy: 0.8703\n",
      "Epoch 5/10\n",
      "83/83 [==============================] - 18s 216ms/step - loss: 0.2570 - accuracy: 0.8866\n",
      "Epoch 6/10\n",
      "83/83 [==============================] - 18s 214ms/step - loss: 0.2394 - accuracy: 0.8889\n",
      "Epoch 7/10\n",
      "83/83 [==============================] - 18s 216ms/step - loss: 0.2292 - accuracy: 0.8950\n",
      "Epoch 8/10\n",
      "83/83 [==============================] - 18s 216ms/step - loss: 0.2141 - accuracy: 0.9109\n",
      "Epoch 9/10\n",
      "83/83 [==============================] - 18s 217ms/step - loss: 0.1960 - accuracy: 0.9135\n",
      "Epoch 10/10\n",
      "83/83 [==============================] - 18s 216ms/step - loss: 0.1941 - accuracy: 0.9188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2481cd47190>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating and training neural networks\n",
    "model_cs = ResNet50(include_top=False,weights=\"imagenet\")\n",
    "x = model_cs.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation=\"relu\")(x)\n",
    "pred = Dense(train_img.num_classes,activation='softmax')(x)\n",
    "model = Model(inputs=model_cs.input,outputs=pred)\n",
    "for layer in model_cs.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_img, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e77e8435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T00:07:32.577968Z",
     "start_time": "2022-10-03T00:07:27.180048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 5s 202ms/step - loss: 0.3560 - accuracy: 0.8439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3559737205505371, 0.8439394235610962]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d993654",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T00:08:49.744373Z",
     "start_time": "2022-10-03T00:07:56.501797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "83/83 [==============================] - 9s 104ms/step - loss: 2.6170 - accuracy: 0.7080\n",
      "Epoch 2/6\n",
      "83/83 [==============================] - 9s 104ms/step - loss: 0.4426 - accuracy: 0.7842\n",
      "Epoch 3/6\n",
      "83/83 [==============================] - 9s 105ms/step - loss: 0.3986 - accuracy: 0.8195\n",
      "Epoch 4/6\n",
      "83/83 [==============================] - 9s 104ms/step - loss: 0.3918 - accuracy: 0.8172\n",
      "Epoch 5/6\n",
      "83/83 [==============================] - 9s 104ms/step - loss: 0.3640 - accuracy: 0.8301\n",
      "Epoch 6/6\n",
      "83/83 [==============================] - 9s 109ms/step - loss: 0.3498 - accuracy: 0.8366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24821c681c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = Sequential([\n",
    "                  layers.Conv2D(32, (2,2), activation='relu', input_shape=(64, 64, 3)),\n",
    "                  layers.MaxPooling2D(3,3),\n",
    "                  layers.Conv2D(64, kernel_size=(3,3),activation='relu',kernel_initializer='he_normal'),\n",
    "                  layers.MaxPooling2D(2,2),\n",
    "                  #layers.Conv2D(64, (2, 2), activation='relu'),\n",
    "                  layers.Conv2D(64, kernel_size=(2,2),activation='relu',kernel_initializer='he_normal'),\n",
    "                  layers.MaxPooling2D(2,2),\n",
    "                  layers.Flatten(),\n",
    "                  layers.Dense(128,activation='relu'),\n",
    "                  layers.Dense(2,activation='softmax',kernel_initializer='glorot_normal')\n",
    "                  \n",
    "])\n",
    "cnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "cnn.fit(train_img, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53c1b340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T00:08:54.529305Z",
     "start_time": "2022-10-03T00:08:52.159336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 88ms/step - loss: 0.3812 - accuracy: 0.8061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3811641335487366, 0.8060606122016907]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0ac9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f0f218f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T00:24:40.915475Z",
     "start_time": "2022-10-03T00:24:40.841215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'malignant'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = load_img('54.jpg', target_size = (64, 64))\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "#training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'benign'\n",
    "else:\n",
    "    prediction = 'malignant'\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "199f3673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T00:22:54.732641Z",
     "start_time": "2022-10-03T00:22:54.665878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'malignant'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = load_img('3.jpg', target_size = (64, 64))\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "#training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'benign'\n",
    "else:\n",
    "    prediction = 'malignant'\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
